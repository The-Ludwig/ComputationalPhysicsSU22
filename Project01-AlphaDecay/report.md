---
title: Computational Physics -- 1 -- The Alpha Decay
author:
- Ludwig Neste
header-includes: |
    \usepackage{multirow}
nocite: |
  @*
abstract:
    'The alpha decay puzzle is the observation, that the lifetime of an alpha-emitter 
    seems to be very sensitive on the energy released per alpha-particle.
    Thus, a model of how an alpha-decay is happening is needed, 
    with which we can predict the lifetime of different nuclei.
    Such a model is developed an numerically solved. 
    Predicted lifetime dependen on different parameters are compared 
    to real-life measurements.
    '
...

# The Physical Problem
An alpha decay is the nuclear decay where a mother-nucleus $(Z, N)$
^[This means a nucleus with $Z$ protons and $N$ neutrons]
decays into the daughter-nucleus $(Z-2, N-2)$ by emitting 
a Helium-4 nucleus $(2, 2)$, also called $\alpha$-particle.
It was experimentally observed that the lifetime of different
nuclei with this decay varies nearly over 30 orders of magnitude, 
while the energy of the released $\alpha$-particle only 
ranges from about 1 to 10 $\mathrm{MeV}$. 
The lifetime is correlated with the energy of the $\alpha$-particle:
the greater the lifetime of the nucleus, the smaller the energy.
We would like to predict the lifetime of nuclei, given 
their binding energy and see if we can find a model 
to match the correlation of lifetime and energy.
The (kinetic) energy $E$ of the alpha particle after 
the decay is coming from the mass-difference of the daughter particles compared 
to the mother particle:
$$
E = (M_{\mathrm{Mother}}-M_{\mathrm{Daughter}}-M_{\alpha})c^2
=
E_{\mathrm{bind,Mother}}-E_{\mathrm{bind,Daughter}}-E_{bind,\alpha}.
$$
Where the formulation with the binding energies is equivalent, since 
the mass of the constituents cancels out.

We model the system of the mother-nucleus as an alpha-particle trapped inside 
the nuclear potential generated by the daughter-nucleus.
Outside the nucleus the only potential is that generated by the Coulomb force 
$$
V_C(r) = \alpha \hbar c \frac{Z_D Z_\alpha}{r}.
$$
Here we already used a form with useful units for the problem at hand: $\alpha = \frac{1}{137.035399}$,
$\hbar c = 197.3269631 \mathrm{MeV/fm}$.
$Z_D$ is the number of protons in the daughter particle and $Z_\alpha=2$.

With only the Coulomb force, the nucleus would not stick together, as it contains only positive charges. 
Close to/inside the nucleus also the *strong nuclear force* starts acting. 
We can model it as a constant negative potential, which only starts acting at 
radii smaller than some $R$.
$$
V_S(r) = \begin{cases}
 0 \quad & r> R\\
 V_0 \quad & r \leq R
\end{cases}
$$
Where $V_0=-134\mathrm{MeV}$ is a typical value, we are going to use.
Inside the nucleus the Coulomb force is still acting, but not like a point source as 
in our previous model, because of the non-zero size of the nucleus.
We will in a first simple model consider this with a constant Coulomb potential 
inside the nucleus with the value $V_C(R)$.
This gives a total nuclear potential $V_N(r)$ of 
$$
V_N(r) = \begin{cases}
 \alpha \hbar c \frac{Z_D Z_\alpha}{r}. \quad & r> R\\
 V_0 + \alpha \hbar c \frac{Z_D Z_\alpha}{R}\quad & r \leq R
\end{cases}.
$$
An example of this potential can be seen in \autoref{fig:pot_example}.
The size $R$ of the nucleus can be modeled as  
$$
R = R_0 \sqrt[3]{A}.
$$ 
Where the value $R_0$ can be thought of as the average radius of the 
protons/neutrons and $A=Z+N$ is the number of particles inside 
the nucleus. The scaling with the third root originates from 
the *Bethe-Weizäcker* Drop-Model, where the nucleus is modeled as 
a drop and the Volume is scaling with the radius to the third power.
The typical value range is between $1.3\mathrm{fm}$ and $1.5\mathrm{fm}$.

![The nuclear potential in our simple model of U-238 with $R=8.05\mathrm{fm}$ \label{fig:pot_example}](build/output/pdf/barriers_test_1000-U-238-pot.pdf){ width=80% }

![The more realistic nuclear potential of U-238 with $R=8.05\mathrm{fm}$ \label{fig:pot_realistic_example}](build/output/pdf/realistic-U-238-pot.pdf){ width=80% }

This is of course a somewhat basic model of the nucleus. It has several flaws and 
can be extended in multiple ways.
For example to get rid of the jump at $R$ one can 
have a smooth transition of the core potential to zero. 
Also the Coulomb potential inside the nucleus can be modeled 
as if the charge is distributed homogenious in a sphere, 
instead of constant.
B. Buck, A. C. Merchant, S. M. Perez, and P. Tripe 
gave such a model [@realistic]:
$$
V_{MPT} = 
V_0 \frac{1+\cosh(R/a)}{\cosh(r/a)+\cosh(R/a)}+
\begin{cases}
 \alpha \hbar c \frac{Z_D Z_\alpha}{r}. \quad & r> R\\
 \alpha \hbar c \frac{Z_D Z_\alpha}{2R}\left(3-(\frac{r}{R})^2\right)\quad & r \leq R
\end{cases}
$$
where a smoothing parameter $a$ is introduced, for example typically $a=0.55\mathrm{fm}$.


The idea now is to solve the stationary one-dimensional Schrödinger-Equation
$$
-\frac{\hbar^2}{2m} \frac{\partial}{\partial r} \psi(r) = (E-V_N(r))\psi(r)
$$
for the given potential and with that solution the probability of an alpha decay.
To phrase it a little more imaginable: Inside the nucleus the particle is essentially 
trapped inside a box-potential, but it can move to the classically 
forbidden region of $r>R$ by tunneling, since in a finite, constant 
potential barrier, the probability of finding a particle decreases exponentially, but 
does not jump to zero. 
This differential equation is not easily analytically solvable, hence the upcoming numerical discussion.

If we were to have a constant potential $V(r)=V$, the solutions would be 
$$
\psi(r) = Ae^{ikr}+Be^{-ikr},\quad k=\sqrt{2mc^2(V-E)}/\hbar c. \label{eqn:plain_wave}
$$
The complex constants $A$ and $B$ are found through boundary conditions and normalization^[The integral of the wavefunction over the whole space must be 1.]
constraints. Depending on the sign of $V-E$ the solution are either 
oscilating waves ($E>V$) or exponential declines ($E<V$).
 

The probability flux is defined as
$$
J(r) = \frac{i\hbar}{2m} \left(\psi^* \frac{\partial}{\partial r} \psi -\psi \frac{\partial}{\partial r} \psi^*\right)
$$.
For the constant-potential plane wave solution $\psi = A e^{\pm ikx}$ this gives a constant probability flux 
of 
$$
J = \mp|A|^2\frac{\hbar k}{m}
$$

With the probability flux the transmission coeficcent between two regions can be found: 
$$
T = \frac{J(r_{out})}{J(r_{in})}.
$$
With that the lifetime 
$$
\tau = \frac{2R}{vT}
$$
can be found, with the velocity $v$ of the particle. 
In the non-relativistic approximation this is $v=\sqrt{2E/m}$. 
The half-life is 
$$
t_{1/2} = \tau \ln{2}
$$

# Numerical Treatment
The idea of this numerical treatment is to cut up the potential in multiple 
discrete values, so we end up with a potential which is constant in each region.
In each of these constant regions, we get solutions of the form of equation \ref{eqn:plane_wave}.
We can then "connect" these solutions by requiring that the overall wavefunction 
and its derivative is continues. This is necesarry, because we need to take
the second derivate in the Schrödinger equation.

Let's devide the region in $N+2$ areas inbetween the values $0, r_1, \dots, r_N, r_{N+1}$,
where the potential has a constant value of $V_0, \dots, V_{N}$ inbetween.
The $N+1$ wavefunctions $\psi_0, \dots, \psi_N$ are of the form 
$$
\psi_i(r) = A_ie^{ik_ir}+B_ie^{-ik_ir}.
$$
The boundary conditions can now be expressed in a homogeneous linear system of equations:
$$
\begin{pmatrix}
\mathbf{M}_0 &\dots &\mathbf{0} \\
\vdots& \ddots &\vdots \\
0& \dots & \mathbf{M}_N 
\end{pmatrix}
\begin{pmatrix}
A_0\\ B_0 \\ A_1 \\ B_1 
\\ \vdots\\
A_{N-1}\\ B_{N-1} \\ A_N \\ B_N 
\end{pmatrix}
=
\begin{pmatrix}
0\\0\\0\\0\\\vdots\\0\\0\\0\\0
\end{pmatrix}
$$
with the $2\times4$ submatrix 
$$
\mathbf{M}_i = 
\begin{pmatrix}
e^{ik_ir} & e^{-ik_ir} & e^{ik_{i+1}r} & e^{-ik_{i+1}r}\\
ik_ie^{ik_ir} & -ik_ie^{-ik_ir} & ik_{i+1}e^{ik_{i+1}r}& -ik_{i+1} e^{-ik_{i+1}r}
\end{pmatrix}
$$.

Because on the rightmost side we won't have any incoming solutions, we can set $B_N=0$. 
We can furthermore choose some arbitrary Normalization and st $A=1$ and get:
$$
\underbrace{
\begin{pmatrix}
1 & 0 & 0 & 0 & \dots & 0\\
\multicolumn{4}{c}{\mathbf{M}_0} &\dots &\mathbf{0} \\
\multicolumn{4}{c}{\vdots}& \ddots &\vdots \\
\multicolumn{4}{c}{\mathbf{0}}& \dots & \mathbf{M}_N 
\end{pmatrix}}_{\mathbf{A}}
\underbrace{
\begin{pmatrix}
A_0\\ B_0 \\ A_1 \\ B_1 
\\ \vdots\\
A_{N-1}\\ B_{N-1} \\ A_N \\ B_N 
\end{pmatrix}}_{\vec{x}}
=
\underbrace{
\begin{pmatrix}
1\\0\\0\\0\\0\\\vdots\\0\\0\\0\\0
\end{pmatrix}}_{\vec{b}}.
$$
If we solve this problem for $\vec x$, we get 
the transition coefficient with 
$$
T  = \frac{|A_N|^2}{|A_0|^2}\frac{k_N}{k_0} = |A_N|^2\frac{k_N}{k_0}
$$
and we have thus solved the problem.


# Numerical Methods
I solved the numerical problem in \texttt{C++} using the 
numerical library \texttt{Eigen3}.
\texttt{Eigen3} supports sparse matrix operatrions.
The matrix to solve has, as $N$ increases, mostly zeros in it.
It is thus at some $N$ more efficient to only save the non-zero entries,
this is called a sparse operation.
I implemented the system of linear equations as a sparse matrix 
and used the LU-Decomposition to solve the system via \texttt{Eigen::SparseLU}.

# Testing
I tested the simulation by comparing 
the predicted lifetime to measurements of 3 different nuclei:

| Symbol (parent) | $A_{\mathrm{Parent}}$ | $Z_{\mathrm{Parent}}$ | $E_{\mathrm{b,p}}/\mathrm{MeV}$ | $E_{\mathrm{b,d}}/\mathrm{MeV}$ | $t_{1/2}/\mathrm{s}$ | 
| ----------- | ----------- | ----------- | ----------- | ----------- | ----------- |
|U-238 |238 |92 |47.3089 |40.6140  |1.4033e18|
|Po-212|212|84|-10.3694|-21.7480 |299e-9|
|Rn-222|222|86|16.366|8.3516|330350.4|

In my simulation I constantly used $M_\alpha =3727.3793\mathrm{fm}$, 
$V_0=-134\mathrm{MeV}$ and  $E_{\mathrm{b,p}}= 2.4249\mathrm{MeV}$ as the binding energy 
of the alpha particle^[Technically all the binding energies I give here are the mass-excesses. If one does not change between these two, this makes no difference.].

My initial settings for the simulation were $R_0=1.3\mathrm{fm}$ and the last 
position I took into account (cutoff) was $R_{\mathrm{last}}=100\mathrm{fm}$.
My initial method of calculating the potential in one bin was 
to take the average in each bin by integrating over it:
$$
V_{\mathrm{bin}} = \alpha \hbar c \frac{Z_D Z_\alpha}{r_{\mathrm{start}-r_\mathrm{end}}} \ln\frac{r_{\mathrm{start}}}{r_{\mathrm{end}}}.
$$

I started by varying the number of areas $N+2$. I tested $N=1,10,100,1000,2000,10000$.
The lifetime seemed to converge reasonably after $N=1000$. 
So I settled for $N=2000$ as this was reasonably good, regarding the computation time.
With these settings the resulting lifetimes were 

| Symbol (parent) | $t_{1/2}/\mathrm{s}$ Simulated  | $t_{1/2}/\mathrm{s}$ Real | Relative Error |
| ----------- | ----------- | ----------- | ----------- | 
|U-238 |7.8e19|1.4033e18|5490%|
|Po-212|7.2e-6|299e-9|2312%|
|Rn-222|3.7e7|330350.4|11134%|.
The potentials for $N=1, 10, 100, 1000$ can be seen in \autoref{fig:N_1} to \autoref{fig:N_21000}.

![Potentials for N=1\label{fig:N_1}](build/output/pdf/barriers_test_1-pot.pdf){ width=80% }

![Potentials for N=10\label{fig:N_10}](build/output/pdf/barriers_test_10-pot.pdf){ width=80% }

![Potentials for N=100\label{fig:N_100}](build/output/pdf/barriers_test_100-pot.pdf){ width=80% }

![Potentials for N=1000\label{fig:N_1000}](build/output/pdf/barriers_test_1000-pot.pdf){ width=80% }


Next I varied $R_{\mathrm{last}}=10, 100, 300, 1000\mathrm{fm}$, 
where there was huge variation in lifetime, but 300 vs. 1000 seeme
d stable, 
so I chose $R_{\mathrm{last}}=300\mathrm{fm}$, the results were:

| Symbol (parent) | $t_{1/2}/\mathrm{s}$ Simulated  | $t_{1/2}/\mathrm{s}$ Real | Relative Error |
| ----------- | ----------- | ----------- | ----------- | 
|U-238 |5.1e19|1.4033e18|3559%|
|Po-212|7.6e-6|299e-9|2464%|
|Rn-222|5.1e7|330350.4|15339%|.

Next I tested for different $R_0$. I tested the values $R_0 = 1.3, 1.4, 1.45, 1.445, 1.5\mathrm{fm}$.
Out of these values I saw that the 'perfect' value is close to 1.445, but I stopped my
testing with this value and settled for $R_0=1.45\mathrm{fm}$, as I did not want to overfit.
Here, the results became reasonable for the first time:

| Symbol (parent) | $t_{1/2}/\mathrm{s}$ Simulated  | $t_{1/2}/\mathrm{s}$ Real | Relative Error |
| ----------- | ----------- | ----------- | ----------- | 
|U-238 |9.4e17|1.4033e18|-32.6%|
|Po-212|2.8e-7|299e-9|-6.2%|
|Rn-222|1.2e6|330350.4|289.1%|.

Then I wanted to understand how the choice of the exact potential value inside the 
bin would matter. 
I tested the already mentioned integrated average, potential at left bin edge, potential 
at right bin edge and potential in the middle of the bin. 
The lifetime did not really change a lot, depending on this choice. 
The integrated value seemed to still work the best. For comparison, here are the lifetimes 
with the potential in the middle of the bin:

| Symbol (parent) | $t_{1/2}/\mathrm{s}$ Simulated  | $t_{1/2}/\mathrm{s}$ Real | Relative Error |
| ----------- | ----------- | ----------- | ----------- | 
|U-238 |9.4e17|1.4033e18|-32.63%|
|Po-212|2.8e-7|299e-9|-6.3%|
|Rn-222|1.2e6|330350.4|288.9%|.

Last but not least, I tested the more realistic potential 
mentioned in the beginning (with the potential taken in the middle of each bin).
I had no time to undergo extensive testing of this potential, so there might still be 
some errors. 
I noticed, that I probably have to choose a different $R_0$ with this potential,
as the meaning of $R_0$ is not a hard cut anymore. The lifetimes got worse, except 
for Rn-222, which performed significantly better:

| Symbol (parent) | $t_{1/2}/\mathrm{s}$ Simulated  | $t_{1/2}/\mathrm{s}$ Real | Relative Error |
| ----------- | ----------- | ----------- | ----------- | 
|U-238 |6.0e17|1.4033e18|-57.22%|
|Po-212|4.8e-8|299e-9|-83.86%|
|Rn-222|266299|330350.4|-19.39%|.

This could mean that this potential models a big range of different nuclei better.


# Problems
While writing this exercise I encountered multiple problems related to programming.
It took a while to set up the \texttt{C++} environment and make 
\texttt{C++} export the data in a python-friendly format for plotting.

Also, I eventually introduced a lot of bugs, related to the construction of the matrix, 
the handling of complex numbers and wrong units.
I basically solved these errors by extensive testing and reiterating and foremost 
by comparing my results and my code to that of other participants of the course. 

I originally also wanted to plot the square of the probability function, 
but I fear I still have some error in my code, as the results do not 
look as I expect them to look. 
The probability function does not start oscillating again after entering the Coulomb barrier, see
\autoref{fig:attempt}.

![Attempted plot of the square of the probability function\label{fig:attempt}](build/output/pdf/realistic-U-238-pdf.pdf){ width=80% }

# Conclusion
Overall, this simulation was able to reproduce approximately correct lifetime.
It generated the huge variance in lifetime.

Still, there are more improvements to be done.
Obviously, it would be nice if the probability density function would 
plot correctly. 
Aside from visualization, if I had more time, I would test the different parameters 
in a more systematic way, rather than testing a few different ones.
A more complete set of $\alpha$-emitters to have more test data would also be nice.
There are still some slight errors in the code: For example I calculate the 
energy of the $\alpha$-particle with the mass of the $\alpha$-particle,
but I should use the reduced mass. However, since the mass of the 
mother particles is at lest 20 times bigger, than that of the $\alpha$-particle,
the reduced mass will be very close to the $\alpha$-particle mass. 

A different thing to test out is what to do with the potential at the last bin.
I introduced a cutoff $R_{\mathrm{last}}$, after which I set the potential to 0.
It can improve the model to set the last potential to a constant 
height, for example the average of the potential form $R_\mathrm{last}$ to 
$\infty$.

Another great feature to introduce would be 
variable bin-width: 
One could set the bin size proportional 
to the gradient of the potential, so that 
if the potential varies a lot, we can divide 
it more often, compared to when it is relatively constant.

# References